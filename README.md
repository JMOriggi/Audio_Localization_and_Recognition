# Audio_Localization_and_Recognition

## Moment localization in video using textual queries
Localizing video moments that
match to a query sentence is a challenging task. It requires
both understanding of language query and video. In addition
to that it requires comprehending the relationship between
vision and language. Recently, significant progress
has been achieved at video grounding task.
Current methods can be grouped into two categories as
the ones use a two-stage pipeline and the ones use a onestage
pipeline. Most of the current language-queried video
grounding methods use the two-stage pipeline
where they first generate moment candidates and calculate
similarity scores between these candidates and query sentence.

![Alt text](/git-docs/2D_TAN.JPG) 

Reference paper [2D-TAN_paper_link](https://arxiv.org/pdf/1912.03590.pdf)
